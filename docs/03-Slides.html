<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Pedro J. Pérez" />


<title>Notes on Applied VAR Modelling</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/united.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<script src="site_libs/htmlwidgets-1.5.1/htmlwidgets.js"></script>
<script src="site_libs/viz-1.8.2/viz.js"></script>
<link href="site_libs/DiagrammeR-styles-0.2/styles.css" rel="stylesheet" />
<script src="site_libs/grViz-binding-1.0.5.9000/grViz.js"></script>
<link href="site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
<link href="site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css" data-origin="pandoc">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */

</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    for (var j = 0; j < rules.length; j++) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") continue;
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') continue;
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>


<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>

<link rel="stylesheet" href="styles.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-inverse  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">VAR models</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">
    <span class="fa fa-home"></span>
     
  </a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="01-Course-plan.html">Course "plan"</a>
</li>
<li>
  <a href="02-Logistics.html">
    <span class="fa fa-laptop"></span>
     
    Logistics
  </a>
</li>
<li>
  <a href="03-Slides.html">
    <span class="fa fa-book"></span>
     
    Slides
  </a>
</li>
<li>
  <a href="04-Lab-Gali.html">
    <span class="fa fa-keyboard"></span>
     
    Lab
  </a>
</li>
<li>
  <a href="05-Schedulle.html">
    <span class="fa fa-calendar-alt"></span>
     
    Schedulle
  </a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-gear"></span>
     
    MáS
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">In Spanish</li>
    <li>
      <a href="tt_01_primeros-pasos-con-R.html">Primeros pasos con R</a>
    </li>
    <li>
      <a href="tt_02_Rmarkdown.html">Rmarkdown</a>
    </li>
  </ul>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Notes on Applied VAR Modelling</h1>
<h4 class="author">Pedro J. Pérez</h4>
<h4 class="date">2020, April</h4>

</div>


<!--- definiendo estilos CSS o HTML -->
<style>
  p {margin: 40px 0 40px 0;}  #- top, izquierda, abajo, left
</style>
<style>
  body { line-height:1.6;}   #- anchura de las lineas 1.0 is the default in Firefox. 2.0 provides a large space
</style>
<style>
  h1, h2, h3, h4, h5  {color:darkblue;}  #- esto me hace los h2 en blue
</style>
<!--- definiendo opciones globales para los chunks -->
<hr />
<div id="notes-on-applied-var-modelling" class="section level1">
<h1>Notes on Applied VAR Modelling</h1>
<hr />
<ol style="list-style-type: decimal">
<li>Introduction</li>
<li>VAR models in reduced form (Estimation)
<ul>
<li>Model Specification</li>
<li>Estimation</li>
<li>Validation</li>
</ul></li>
<li>VAR models in reduced form (Uses)
<ul>
<li>Causality Analysis</li>
<li>Forecasting</li>
<li>Moving average representation (MVA)</li>
<li>Structural analysis
<ul>
<li>Impulse response functions (IRF)</li>
<li>Forecast Error Variance Decomposition (FEVD)</li>
<li>Historical Decomposition</li>
</ul></li>
</ul></li>
<li>Structural VAR models
<ul>
<li>Introduction</li>
<li>Identification with short-run restrictions (on the effects of shocks)</li>
<li>Identification with long-run restrictions (on the effects of shocks)</li>
<li>Identification with contemporaneous interactions among the endogenous variables</li>
<li>Identifying the SVAR by both types of restrictions (The AB-model)</li>
</ul></li>
</ol>
<p><br></p>
<hr />
</div>
<div id="introduction" class="section level1">
<h1>1. Introduction</h1>
<ul>
<li><p>Most of the questions in empirical macroeconomics are similar to: what is the effect of a policy intervention or shock (interest rate increase, tax cut, … ) on the macroeconomic aggregates of interest?</p></li>
<li>Ideally, we would like to know the dynamic effect of a shock (<span class="math inline">\(\varepsilon_{t}\)</span>) on { <span class="math inline">\(Y_{t},Y_{t+1}\)</span>, … }
<ul>
<li><p>In macro, this dynamic causal effect is called the impulse response function (IRF) of <span class="math inline">\(Y_{t}\)</span> to the shock <span class="math inline">\(\varepsilon_{t}\)</span></p></li>
<li><p>That’s the typical purpose of <strong>Vector Autoregressive (VAR) models</strong>: to estimate the IRF of a macroeconomic series (<span class="math inline">\(Y_{t}\)</span>) to a shock (<span class="math inline">\(\varepsilon_{t}\)</span>)</p></li>
</ul></li>
<li><p>During the three decades following <a href="https://ideas.repec.org/a/ecm/emetrp/v48y1980i1p1-48.html">Sims’s (1980) paper</a>, VAR models have become a standard instrument in econometrics to analyse multivariate time series and one of the major ways to obtain information about the economy</p></li>
<li><p>VAR’s have proven their worth in forecasting, but also in uncovering the transmission mechanisms of key macroeconomic shocks. In particular VAR’s:</p>
<ul>
<li><p>have a central role in investigating the sources of business cycle fluctuations</p></li>
<li><p>have become a benchmark instrument against which modern dynamic theories (DSGE models) are evaluated</p></li>
</ul></li>
<li><p>After identification, <strong>Structural Vector Autoregressive (SVAR) models</strong> have been mainly used to address the 2 following type of questions:</p>
<ul>
<li><p>How does the economy (<span class="math inline">\(Y_{t}\)</span>) respond to different economic shocks? (<strong>IRF</strong>)</p></li>
<li><p>What is the contribution of the different shocks to the movements in <span class="math inline">\(Y_{t}\)</span>? (<strong>FEVD</strong>)</p></li>
</ul></li>
<li><p>SVAR’s have been used in an incredibly large number of areas and topics, and have had and continue to have a central role for understanding aggregate fluctuations and disentangling the importance of different economic shocks</p></li>
</ul>
<p>As <a href="https://ideas.repec.org/p/cpr/ceprdp/8515.html">Kilian (2011)</a> says:</p>
<blockquote>
<p>Notwithstanding the increased use of estimated dynamic stochastic general equilibrium (DSGE) models over the last decade, <strong>structural vector autoregressive (VAR) models continue to be the workhorse of empirical macroeconomics and finance</strong></p>
</blockquote>
<p><br></p>
<div id="origins-development-of-var-models" class="section level2">
<h2>1.1 Origins &amp; development of VAR models</h2>
<ul>
<li><p>Origins: <a href="https://ideas.repec.org/a/ecm/emetrp/v48y1980i1p1-48.html">Sims (1980)</a> in his paper Macroeconomics and Reality</p></li>
<li><p>A little bit of history: In the mid 70’s, Cowles Commission’s approach to econometric modelling was attacked on several grounds and was eventually abolished. Two major critiques:</p>
<ul>
<li><p><strong>Lucas critique</strong>: expectations are not taken into account explicitly, so identified parameters are a mixture of deep parameters (preference and technology) and expectational parameters that are not stable across policy regimes(parameter invariance). Hence, models are not useful for policy simulations</p></li>
<li><p><strong>Sims “critique”</strong>: “incredible identification restrictions”. Sims raised several objections to the traditional way of identifying macroeconometric models, where exclusion restrictions were routinely imposed and the decision whether a variable should be regarded as exogenous with respect to the system was made rather arbitrarily. In particular, according to Sims, no variable can be deemed as exogenous in a world of rational forward looking agents.</p></li>
</ul></li>
<li><p>Sims (1980) advocates for the use of VAR models as a theory-free method to estimate economic relationships</p>
<ul>
<li><p>Sims’s basic idea was to treat all variables as endogenous and first estimate an unrestricted model in a reduced form. No prior knowledge is used except to decide which variables should enter the system.</p></li>
<li><p>The estimation of the VAR is usually made by OLS (which we will see is consistent and, under normality of the error terms, efficient)</p></li>
<li><p>Once the VAR is estimated, different analysis could be done but the most usual are the obtaining of IRF and FEVD, but for this, the structural shocks should be identified</p></li>
<li><p>Guided by economic theory, the econometrician imposes restrictions (usually on how the structural shocks impact the variables within the model system) transforming the VAR model into a Structural Vector Autoregressive (<strong>SVAR</strong>) model</p></li>
<li><p>Sims’s original idea to obtain IRF&amp;FEVD was to assume recursive contemporaneous interactions among variables, i.e. by imposing a certain structural ordering of the variables. In terms of the moving average (MA) representation, the structural shocks do not affect preceding variables simultaneously (Cholesky)</p></li>
<li><p>Later on, restrictions to obtain the SVAR, came in several forms: general short run restrictions, (zero or linear relationships), long run restrictions, cointegration and sign restrictions, etc.</p></li>
</ul></li>
</ul>
<p><br></p>
</div>
<div id="a-guided-tour-through-var-methodology" class="section level2">
<h2>1.2 A guided tour through VAR methodology:</h2>
<div id="htmlwidget-ce8f821458d21c7f4162" style="width:672px;height:480px;" class="grViz html-widget"></div>
<script type="application/json" data-for="htmlwidget-ce8f821458d21c7f4162">{"x":{"diagram":"\ndigraph org{\nlayout = dot\nnode [shape=\"box\"]\n1[label=\"Specification & Estimation of VAR (in reduced form)\"]\n2[label=\"Model Cheking\", fontcolor=\"red\"] \n1 -> 2\nedge [color=\"brown\",penwidth=2]\n2 -> 1\nnode [shape=\"box\"]\na[label=\"Forecasting\"]\nb[label=\"Causality\"]\nc[label=\"Structural Analysis\"]\nedge [color=\"black\",penwidth=1]\n2 ->  {a b c}\nnode [shape=\"box\", fixedsized = false]\nw[label=\"Forecast scenarios\"]\nx[label=\"Historical decompositions\"]\ny[label=\"IRFs\"]\nz[label=\"FEVD\"]\nc ->  {w x y z }\n} \n","config":{"engine":"dot","options":null}},"evals":[],"jsHooks":[]}</script>
<p>Similar to Figure 1, p.3, in <a href="http://cadmus.eui.eu/bitstream/handle/1814/19354/ECO_2011_30.pdf">Lütkepohl(2011)</a></p>
<p><br></p>
<hr />
<p><br></p>
</div>
</div>
<div id="var-models-in-reduced-form" class="section level1">
<h1>2. VAR models (in reduced form)</h1>
<p>As we will see in short, there are different representations for a VAR: VAR vs. VMA, structural vs. reduced VAR’s. By now we will start with a question:</p>
<div id="what-is-exactly-a-var-model" class="section level4">
<h4>What is exactly a VAR model?</h4>
<ul>
<li><p>A VAR is an econometric model used to capture the linear interdependencies among multiple time series. In fact, a VAR(p) is a generalization of the AR(p) model to the multivariate case.</p></li>
<li><p>All variables in a VAR are treated symmetrically: each variable has an equation explaining its evolution based on its own lags and the lags of the other model variables</p></li>
<li><p>A VAR analysis starts by estimating a (reduced form) VAR model of order p.</p></li>
</ul>
<p><br></p>
</div>
<div id="an-example-a-trivariate-varp2-model" class="section level4">
<h4>An example: a trivariate VAR(p=2) model</h4>
<ul>
<li><p>trivariate: {GDP, Prices, Money}:</p>
<ul>
<li><p>two lags (p=2)</p></li>
<li><p>all variables I(0)!!!</p></li>
</ul></li>
</ul>
<p><span class="math display">\[\left\{ 
\begin{array}{c}
Y_{t}=0.6Y_{t-1}+0.2Y_{t-2}+0.3P_{t-1}-0.2P_{t-2}+0.5M_{t-1}-0.5M_{t-2}+v_{t}^{Y}
\\ 
P_{t}=-0.7_{t-1}+0.1_{t-2}+0.5P_{t-1}+0.4P_{t-2}+0.6M_{t-1}-0.6M_{t-2}+v_{t}^{P}
\\ 
M_{t}=-0.6_{t-1}+0.3_{t-2}+0.5P_{t-1}+0.4P_{t-2}+0.9M_{t-1}-0.2M_{t-2}+v_{t}^{M}%
\end{array}%
\right\} \]</span></p>
<ul>
<li>The variables could be arranged in different ways, but the most common way of visualization is:</li>
</ul>
<p><span class="math display">\[%
\begin{array}{c}
Y_{t}=0.6Y_{t-1}+0.3P_{t-1}+0.5M_{t-1}+0.2Y_{t-2}-0.2P_{t-2}-0.5M_{t-2}+v_{t}^{Y}
\\ 
P_{t}=-0.7Y_{t-1}+0.5P_{t-1}+0.6M_{t-1}+0.1Y_{t-2}+0.4P_{t-2}-0.6M_{t-2}+v_{t}^{P}
\\ 
M_{t}=-0.6Y_{t-1}+0.5P_{t-1}+0.9M_{t-1}+0.3Y_{t-2}+0.4P_{t-2}+-0.2M_{t-2}+v_{t}^{M}%
\end{array}%\]</span></p>
<ul>
<li>We can simplify the visualization of the VAR by defining the following vectors:</li>
</ul>
<p><span class="math display">\[y_{t}=\left[ 
\begin{array}{c}
Y_{t} \\ 
P_{t} \\ 
M_{t}%
\end{array}%
\right] \ \ \ \ \ v_{t}=\left[ 
\begin{array}{c}
v_{t}^{Y} \\ 
v_{t}^{P} \\ 
v_{t}^{M}%
\end{array}%
\right] \]</span></p>
<ul>
<li>Then, the VAR could be written as:</li>
</ul>
<p><span class="math display">\[y_{t}=\left[ 
\begin{array}{ccc}
0.6 &amp; 0.3 &amp; 0.5 \\ 
-0.7 &amp; 0.5 &amp; 0.6 \\ 
-0.6 &amp; 0.5 &amp; 0.9%
\end{array}%
\right] y_{t-1}+\left[ 
\begin{array}{ccc}
0.2 &amp; -0.2 &amp; -0.5 \\ 
0.1 &amp; 0.4 &amp; -0.6 \\ 
0.3 &amp; 0.4 &amp; -0.2%
\end{array}%
\right] y_{t-2}+v_{t}\]</span></p>
<ul>
<li>As well as:</li>
</ul>
<p><span class="math display">\[y_{t}=A_{1}y_{t-1}+A_{2}y_{t-2}+v_{t}\]</span></p>
<ul>
<li>And, also more compactly, as:</li>
</ul>
<p><span class="math display">\[A(L)y_{t}=v_{t}\]</span></p>
<p>with <span class="math inline">\(A(L)=(I_{K}-A_{1}L^{1}-A_{2}L^{2})\)</span></p>
<ul>
<li><p>After estimation &amp; validation, a VAR (in reduced form) could be used for testing (for example, Granger causality) and for forecasting</p></li>
<li><p>The principal instruments (or usages) of VAR modelling are the IRF &amp; FEVD but for these uses it’s necessary to identify the structural disturbances, that is, to estimate a SVAR model</p></li>
</ul>
<p><br></p>
<hr />
</div>
<div id="model-specification" class="section level2">
<h2>2.1 Model Specification</h2>
<p><br></p>
<ul>
<li>Let <span class="math inline">\(y_{t~}=~\left[ Y_{1t~},~Y_{2t}~,~....~,~Y_{Kt}\right] ^{^{\prime}}\)</span> denote a (Kx1) vector of random variables, then a VAR(p) model can be written as :</li>
</ul>
<p><span class="math display">\[y_{t}~=A_{1}y_{t-1}+A_{2}y_{t-2}+\ \ ...\ \
+A_{p}y_{t-p}+CD_{t}+v_{t}\ \ \ \ \ \ \ \ [1]\]</span></p>
<p>where:</p>
<p><span class="math inline">\(\boldsymbol{D_{t}}\)</span> is a vector <span class="math inline">\((M\times 1)\)</span> with the appropriate deterministic regressors (constant, trend, dummies …), <span class="math inline">\(\boldsymbol{C}\)</span> is the coefficient matrix for <span class="math inline">\(\boldsymbol{D_{t}}\)</span></p>
<p><span class="math inline">\(\boldsymbol{A_{i}}\)</span> are <span class="math inline">\((K\times K)\)</span> coefficient matrices,<br />
<span class="math inline">\(\boldsymbol{v_{t}}\)</span> is a <span class="math inline">\((K\times 1)\)</span> vector of white noise (<span class="math inline">\(v_{t}\rightarrow (0,\Sigma _{v})\)</span>).</p>
<p><br></p>
<ul>
<li>As Lütkepohl (2011) points out:</li>
</ul>
<blockquote>
<p>Using terminology from the simultaneous equations literature, the VAR model [1] is in reduced form because all right-hand side variables are lagged or predetermined.</p>
</blockquote>
<ul>
<li>Be aware that, for a VAR (in reduced form):</li>
</ul>
<blockquote>
<p>The instantaneous relations between the variables are summarized in the residual covariance matrix</p>
</blockquote>
<p><br></p>
<div id="a-compact-way-to-write-a-varp-model" class="section level3">
<h3>A compact way to write a VAR(p) model</h3>
<ul>
<li>For simplicity in the notation, let’s suppose that the deterministic part of our VAR(p) model is zero; then our VAR(p) would be :</li>
</ul>
<p><span class="math display">\[y_{t}~=A_{1}y_{t-1}+A_{2}y_{t-2}+\ \ ...\ \
+A_{p}y_{t-p}+v_{t}\ \ \ \ \ \ \ \ \ \ [2]\]</span></p>
<p>Model <span class="math inline">\([2]\)</span> can be written using a polynomial in the lag operator as:</p>
<p><span class="math display">\[A(L)y_{t}=v_{t}\ \ \ \ \ \ \ \ \ \ [3]\]</span></p>
<p>with <span class="math inline">\(A(L)=(I_{K}-A_{1}L^{1}-A_{2}L^{2}-...-A_{p}L^{p})\)</span></p>
<p><br></p>
</div>
<div id="stability-of-the-varp" class="section level3">
<h3>Stability of the VAR(p)</h3>
<ul>
<li><p>An important issue in VAR modelling is <strong>stability</strong></p></li>
<li><p>The VAR(p) process is stable if all roots of the determinantal polynomial (<span class="math inline">\(\det A(z)=\det (I_{K}-A_{1}z^{1}-A_{2}z^{2}-...-A_{p}z^{p})=0\)</span>) are outside the complex unit circle (or equivalently if the eigenvalues of the companion matrix have modulus less than one)</p></li>
<li><p>Under habitual assumptions, a stable process is covariance stationary. Then, if the VAR is stable, the variables in <span class="math inline">\(y_{t}\)</span> would be <span class="math inline">\(I(0)\)</span>, and in this case we could estimate the VAR with the variables in levels (VAR in levels).</p></li>
<li><p>But, if the solution of the above equation, <span class="math inline">\(\det A(z)=0\)</span>, has a root for <span class="math inline">\(z=1\)</span>, that is, if the process has a unit root, then some (or all) variables in the VAR(p) are <span class="math inline">\(I(1)\)</span>. Then the process is nonstationary and before starting the analysis we should transform the variables to reach stationarity; usually by first differences (VAR in first differences)</p></li>
<li><p>If some of the variables are I(1), then we have to check the possibility that cointegration exits. If that was the case, a VECM should be used.</p></li>
</ul>
<p><br></p>
<hr />
</div>
</div>
<div id="estimation" class="section level2">
<h2>2.2 Estimation</h2>
<p>VAR models can be estimated with standard methods: OLS or ML. VAR models can also be estimated by Bayesian methods</p>
<ul>
<li><p>As all the equations in the VAR share the same set of regressors and all of them are lagged variables, the VAR could be estimated efficiently by OLS for each equation separately.</p></li>
<li><p>If the residuals are normally distributed (Gaussian) like (<span class="math inline">\(v_{t}\rightarrow N(0,\Sigma _{v})\)</span>) the <strong>OLS estimator of our VAR model will have desirable asymptotic properties</strong>: it will be asymptotically normally distributed and will have the smallest asymptotic covariance matrix</p></li>
<li><p>Then, if the VAR is stable, usual inference procedures are asymptotically valid: t-statistics could be used for inference about individual parameters and the F-test could be used for testing hypotheses for sets of parameters.</p></li>
<li><p>Note also that if <span class="math inline">\(y_{t}\)</span> is a normally distributed (Gaussian) process, then the OLS estimator is identical to the ML estimator (conditional on the initial pre-sample values).</p></li>
<li><p>If restrictions are imposed on the parameters, OLS estimation may be inefficient. In that case GLS estimation may be beneficial. The GLS estimator is consistent and asymptotically normally distributed and usual methods for inference are valid asymptotically.</p></li>
<li><p>Note that if the disturbances in one equation are for example autocorrelated, the theory does not apply. Then IV estimators, including GMM, would be needed.</p></li>
<li><p>Under-specification of p might result in autocorrelated residuals</p></li>
</ul>
<div id="how-to-estimate-a-var-model-in-r" class="section level3">
<h3>How to estimate a VAR model in R?</h3>
<ul>
<li><p>We are going to use the R package <code>vars</code> written by Bernhard Pfaff. A short description of the functionalities of the Pfaff’s package can be found <a href="http://www.jstatsoft.org/v27/i04/paper">here</a>. For a more detailed exposition, please go <a href="http://cran.r-project.org/web/packages/vars/vars.pdf">here</a></p></li>
<li><p>To illustrate the different topics in VAR modelling, we are going to use as an example the analysis and data used in <a href="http://crei.cat/people/gali/jgaer99.pdf">Gali’s (1999)</a> paper : &quot;Technology, Employment, and the Business Cycle: Do Technology Shocks Explain Aggregate Fluctuations?</p></li>
<li><p>In his paper, Gali estimates a bivariate VAR for productivity and hours to look mainly at the response of hours to a technology shock</p></li>
<li><p>In fact we are going to “replicate” Gali’s paper but only for his benchmark model:</p>
<ul>
<li><p>U.S. quarterly data for <strong>1948:1 - 1994:4</strong> from Citibase</p></li>
<li><p>bivariate VAR model: productivity(<span class="math inline">\(x_{t}\)</span>) and hours(<span class="math inline">\(n_{t}\)</span>)</p></li>
<li><p><span class="math inline">\(y_{t~}=~\left[ x_{t~},n_{t}\right] ^{^{\prime }}\)</span>, both variables in (log) <strong>first differences</strong></p></li>
</ul></li>
</ul>
<p><br></p>
<div id="lets-open-the-lab-slides" class="section level4">
<h4>Let’s open the LAB slides</h4>
<p><br></p>
<hr />
</div>
</div>
<div id="model-specification-1" class="section level3">
<h3>Model Specification</h3>
<p>Imagine that we have already decided wchich variables to include in our VAR model, the sample, if the variables are I(1) vs. I(0) , and the deterministics components . In this case we have almost finished the model specification. Almost, because … we need to decide the order of the VAR.</p>
<div id="how-to-select-p-the-order-of-the-var" class="section level4">
<h4>How to select (p) the order of the VAR?</h4>
<p>For a more detailed exposition go to <a href="http://cadmus.eui.eu/bitstream/handle/1814/19354/ECO_2011_30.pdf">Lütkepohl(2011)</a>, pp. 10-11</p>
<ul>
<li><p>The idea is that we have to select an order(p) sufficiently large to ensure that the residuals shown no autocorrelation but without exhausting the degrees of freedom.</p></li>
<li><p>The order of the VAR could be selected by:</p>
<ol style="list-style-type: decimal">
<li><p>Sequential testing procedures</p></li>
<li><p>Model selection criteria</p></li>
</ol></li>
<li><p><strong>Sequential testing procedures</strong> approach:</p>
<ul>
<li><p>A maximum <em>reasonable</em> lag order(<span class="math inline">\(p_{\max }\)</span>) is chosen</p></li>
<li><p>Then, the following sequence of null hypotheses ios tested: <span class="math inline">\(H_{0}:A_{p_{\max }}=0\)</span> , <span class="math inline">\(H_{0}:A_{p_{\max -1}}=0\)</span>, …</p></li>
<li><p>For a stationary VAR the usual LR test could be used</p></li>
<li><p>The procedure stops when the null hypothesis is rejected for the first time</p></li>
</ul></li>
<li><p><strong>Model selection criteria</strong> approach:</p>
<ul>
<li><p>A model selection criteria is chosen (AIC, HQ, SC, FPE). For multivariate expression of these criteria see <a href="http://cadmus.eui.eu/bitstream/handle/1814/19354/ECO_2011_30.pdf">Lütkepohl(2011)</a></p></li>
<li><p>Again, a maximum <em>reasonable</em> lag order(<span class="math inline">\(p_{\max }\)</span>) is chosen</p></li>
<li><p>A set of VAR(m) are estimated for <span class="math inline">\(m=1,...,~p_{\max }\)</span></p></li>
<li><p>Choose p as the lags of the VAR(m) which minimize the chosen criteria</p></li>
<li><p>AIC usually overestimates p</p></li>
</ul></li>
<li><p>The package “vars” has the <strong>VARselect()</strong> function which allows us to apply the 2<sup>nd</sup> approach to select p.</p></li>
<li><p>As we will see in the LAB slides, three criteria (AIC,HQ &amp;FPE) choose p=2; BUT, as our data are quarterly, probably, as Gali does, a more sensible choice would be p=4</p></li>
</ul>
</div>
<div id="finally-we-are-now-ready-to-estimate-our-var-with-p4.-lets-go-the-lab-slides" class="section level4">
<h4>Finally, we are now ready to estimate our VAR with p=4. Let’s go the LAB slides!!!</h4>
<p><br><br></p>
<hr />
</div>
</div>
</div>
<div id="validation-of-the-var" class="section level2">
<h2>2.3 Validation of the VAR</h2>
<ul>
<li><p>After estimation, and before using or transforming our VAR to a SVAR, we have to check their validity mainly looking at the residuals</p></li>
<li><p>Again, let’s go to the LAB!!!</p></li>
</ul>
<p><br></p>
<hr />
<p><br></p>
</div>
</div>
<div id="var-models-in-reduced-form-uses" class="section level1">
<h1>3. VAR models in reduced form (Uses)</h1>
<p>The two principal uses of VAR models in reduced form are testing (causality testing) and forecasting, BUT the most used instruments in the VAR metholodogy are IRF &amp; FEVD.</p>
<p>IRF &amp; FEVD only have a clear mening if we transform our reduced form VAR model to an structural VAR. We will develop this idea in a while</p>
<div id="uses-of-var-causality-testing" class="section level2">
<h2>3.1 Uses of VAR: Causality testing</h2>
<ul>
<li><p>After validation, the VAR could be used for testing, for example, for testing Granger causality.</p></li>
<li><p>As we said, if the residuals are normally distributed (Gaussian) like (<span class="math inline">\(v_{t}\rightarrow N(0,\Sigma _{v})\)</span>) the <strong>OLS estimator has desirable asymptotic properties</strong>. In particular, it will be asymptotically normally distributed, and then, if the VAR is stable, usual inference procedures are asymptotically valid: t-statistics could be used for inference about individual parameters and F-test for testing hypotheses for sets of parameters.</p></li>
<li><p>Even if t-tests are asymptotically valid, due to collinearity problems, it would not be sensible to interpret or to test only one parameter in isolation.</p></li>
<li><p>In regression analysis, we label one variable as the dependent variable and the others as explanatory. But most of the time, it is not obvious which variable causes which. As you know, we should always be cautious about interpreting correlation and regression results as reflecting causality.</p></li>
<li><p>With time series data we can make slightly stronger statements about causality simply by exploiting the fact that time does not run backward. If event A happens before B, then it’s possible that A causes B, but not that B causes A. These ideas can be investigated through regression models using the notion of Granger causality.</p></li>
<li><p><strong>Granger causality</strong>: Granger called a variable X causal for Y if the information in past and present values of X is helpful for improving the forecast of Y. If Granger causality holds, this does not guarantee that X causes Y. But, it suggests that X might be causing Y.</p></li>
<li><p>Sometimes econometricians use the shorter term <em>causes</em> as shorthand for <em>Granger causes</em>. You should notice, however, that Granger causality is not causality in a deep sense of the word. It just talks about linear prediction, and it only has “teeth” if we only find Granger causality in one direction.</p></li>
<li><p>The definition of Granger causality did not mention anything about possible instantaneous correlation between variables. If the innovations are correlated we will say that there exists instantaneous causality</p></li>
<li><p>In the context of VAR models, if we want to test for Granger causality, we need to test zero constraints in some of the coefficients.</p></li>
<li><p>Suppose that 2 variables ( <span class="math inline">\(y_{1t}\)</span> and <span class="math inline">\(y_{2t}\)</span> ) are generated by a bivariate VAR(p) process like:</p></li>
</ul>
<p><span class="math display">\[\left[ 
\begin{array}{c}
y_{1t} \\ 
y_{2t}%
\end{array}%
\right] =\overset{p}{\underset{i=1}{\sum }}\left[ 
\begin{array}{cc}
\alpha _{11,i} &amp; \alpha _{12,i} \\ 
\alpha _{21,i} &amp; \alpha _{22,i}%
\end{array}%
\right] \left[ 
\begin{array}{c}
y_{1t-i} \\ 
y_{2t-i}%
\end{array}%
\right] +u_{t}\]</span></p>
<ul>
<li>Then, <span class="math inline">\(y_{2t}\)</span> is not Granger-causal for <span class="math inline">\(y_{1t}\)</span> if and only if :</li>
</ul>
<p><span class="math display">\[\alpha _{12,i}=0\ \ ,\ \ i=1,2,\cdots ,p\]</span></p>
<ul>
<li><p>That is, <span class="math inline">\(y_{2t}\)</span> does not Granger cause <span class="math inline">\(y_{1t}\)</span> if <span class="math inline">\(y_{2t}\)</span> does not appear in the equation for <span class="math inline">\(y_{1t}\)</span></p></li>
<li><p>If there are more than 2 variables in the VAR, testing Granger causality becomes more complicated, because Granger-causality depends on the information set considered, but this is beyond the scope of this course. For a complete treatment of the topic see, as usual, <a href="http://www.springer.com/economics/econometrics/book/978-3-540-40172-8">Lütkepohl(2005)</a></p></li>
<li><p>It’s possible to test Granger causality through the Wald or F-test. In the <em>vars</em> package, we can use:</p>
<ul>
<li><p>F-test to test Granger causality</p></li>
<li><p>Wald test for instantaneous Granger causality (non zero correlation among the <span class="math inline">\(v_{it}\)</span>)</p></li>
</ul></li>
</ul>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1-1" data-line-number="1"><span class="co">#-- We can test Granger causality</span></a>
<a class="sourceLine" id="cb1-2" data-line-number="2"><span class="kw">causality</span>(our_var, <span class="dt">cause =</span> <span class="kw">c</span>(<span class="st">&quot;dx&quot;</span>))  <span class="co">#-- dx Granger-cause the other(s) variables?</span></a>
<a class="sourceLine" id="cb1-3" data-line-number="3"><span class="kw">causality</span>(our_var, <span class="dt">cause =</span> <span class="kw">c</span>(<span class="st">&quot;dn&quot;</span>))  <span class="co">#-- dn Granger-cause the other(s) variables?</span></a></code></pre></div>
<p><br></p>
<hr />
</div>
<div id="uses-of-var-forecasting" class="section level2">
<h2>3.2 Uses of VAR: Forecasting</h2>
<ul>
<li><p>We are not going to develop this topic, but … for instance: <a href="https://helda.helsinki.fi/bof/bitstream/handle/123456789/13660/dp1315%5B1%5D.pdf?sequence=1">Real time forecasting with a MIDAS VAR</a></p></li>
<li><p>After validation, a VAR could also be used for forecasting</p></li>
</ul>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb2-1" data-line-number="1"><span class="co">#-- We can use the VAR for forecasting</span></a>
<a class="sourceLine" id="cb2-2" data-line-number="2"><span class="kw">predict</span>(our_var, <span class="dt">n.ahead =</span> <span class="dv">3</span>)</a>
<a class="sourceLine" id="cb2-3" data-line-number="3"><span class="kw">fanchart</span>(<span class="kw">predict</span>(our_var))</a></code></pre></div>
<p><br></p>
<hr />
</div>
<div id="moving-average-representation-mva-of-a-varp" class="section level2">
<h2>3.3 Moving average representation (MVA) of a VAR(p)</h2>
<ul>
<li><p>You all know that stationary AR process could be transformed (inverted) into an infinite MA(<span class="math inline">\(\infty\)</span>) process. This result applies also to a stationary (stable) VAR</p></li>
<li><p>By inverting the autoregressive polynomial A(L) we can obtain the VMA form of a VAR like:</p></li>
</ul>
<p><span class="math display">\[y_{t}~=C_{0}v_{t}+C_{1}v_{t-1}+C_{2}v_{t-2}+\ ...\  [3]\]</span></p>
<p>being <span class="math inline">\(C_{0}=I_{K}\)</span>, the rest of the <span class="math inline">\(C_{s}\)</span> matrices could be computed recursively as</p>
<p><span class="math display">\[C_{s}=\underset{j=1}{\overset{s}{\sum }}C_{s-j}A_{j}\ \ \
\ \ \ \ \ \ for\ j=1,\
2,\cdots \]</span></p>
<p><br></p>
<ul>
<li>As with the VAR, model <span class="math inline">\([3]\)</span> can be written using a polynomial in the lag operator as:</li>
</ul>
<p><span class="math display">\[y_{t}=C(L)v_{t}\ \ \ \ \ \ \ \ \ \ \ \ [4]\]</span></p>
<p>being <span class="math inline">\(C(L)=(I_{K}+C_{1}L^{1}+C_{2}L^{2}+\ \ ...)\)</span>.</p>
<ul>
<li><p>Model <span class="math inline">\([3]\)</span> (or <span class="math inline">\([4]\)</span>) are also called the Wold VMA representation</p></li>
<li><p>The two principal instruments of VAR’s, IRF &amp; FEVD, are defined in terms of their VMA representation [3]</p></li>
<li><p>IRF &amp; FEVD will show the effects of a shock, <strong>BUT</strong> in order to have a clear meaning, they must be interpreted under the assumption that all the other shocks are held constant; however, in the Wold representation the shocks are not orthogonal; that’s why we will turn, in the next section, to <strong>structural VAR models</strong></p></li>
</ul>
<p><br></p>
<hr />
</div>
<div id="uses-of-var-structural-analysis" class="section level2">
<h2>3.4 Uses of VAR: “Structural” analysis</h2>
<ul>
<li><p>Usually the main interest in VAR modelling is to look at the dynamic effect of a shock on the variables of interest</p></li>
<li><p>This dynamic effect could be easily obtained through the VMA representation [3] of the VAR, also called Wold VMA representation</p></li>
<li><p>In particular the response of the variable <span class="math inline">\(y_{n}\)</span> to an impulse of size one in <span class="math inline">\(v_{m}\)</span> <span class="math inline">\(j\)</span>-periods ahead is given by the <span class="math inline">\((n,m)\)</span><em>-th</em> element of <span class="math inline">\(C_{j}\)</span>. That is, the <span class="math inline">\(C_{i}\)</span> matrices contain the responses of the variables to the innovations for different periods (or steps) ahead</p></li>
<li><p>As the <span class="math inline">\(u_{i}\)</span> are forecast error’s, those effects are called forecast error impulse responses or in short impulse response functions (IRF’s)</p></li>
</ul>
<div id="but" class="section level4">
<h4>BUT…</h4>
<ul>
<li><p>BUT, usually the VAR disturbances are correlated, so the interpretability of the impulse responses to innovation becomes problematic: if the innovations are correlated (off diagonal elements of <span class="math inline">\(\Sigma _{v}\)</span> different from zero) then, an impulse in <span class="math inline">\(v_{m}\)</span> would be associated with impulses in innovations in the other equations of the VAR model.</p>
<ul>
<li>In other words, as the innovations are not likely to occur in isolation, then tracking the effect of an innovation in isolation does not reflect what actually happens in the system after an innovation hits the system.</li>
</ul></li>
<li><p>Therefore, Sims proposed assuming recursive contemporaneous interactions among variables, i.e. imposing a certain structural ordering in the variables. In terms of the MVA representation this means that the transformed or “structural” shocks will not affect the preceding variables instantaneously.</p>
<ul>
<li>That means that an innovation in the first equation could contemporaneously affects all the variables in the VAR, while the innovation in the second equation could contemporaneously affect all the variables in the VAR except the first one, … and finally, an innovation in the last equation could contemporaneously affects only the last variable in the VAR</li>
</ul></li>
<li><p>In practice, imposing a recursive contemporaneous order among the variables of the VAR model, is operationalised performing a Cholesky decomposition in <span class="math inline">\(\Sigma _{v}\)</span>. Let’s show that:</p>
<ul>
<li>The Cholesky factor, <span class="math inline">\(P\)</span>, of <span class="math inline">\(\Sigma _{v}\)</span> is defined as the unique lower triangular matrix such that <span class="math inline">\(PP^{^{\prime }}=\Sigma _{v}\)</span></li>
</ul></li>
<li><p>With the Cholesky factor(<span class="math inline">\(P\)</span>) we could transform the VAR in [3] as:</p></li>
</ul>
<p><span class="math display">\[A(L)y_{t}=PP^{-1}v_{t}\]</span></p>
<p>with <span class="math inline">\(\varepsilon _{t}=P^{-1}v_{t}\)</span>, then our transformed VAR becomes</p>
<p><span class="math display">\[A(L)y_{t}=P\varepsilon _{t}\ \ \ \ \ \ \ \ \ \ \ \ [2*]\]</span></p>
<ul>
<li><p>That is, we have written our VAR in terms of a new vector of shocks <span class="math inline">\(\varepsilon _{t}\)</span>, with identity covariance matrix (<span class="math inline">\(\Sigma _{\varepsilon }=I\)</span>)</p></li>
<li><p>Now, as the <span class="math inline">\(\varepsilon _{t}\)</span> shocks are uncorrelated their IRF would have a clear interpretation</p></li>
</ul>
</div>
</div>
<div id="section" class="section level2">
<h2><br></h2>
<div id="irf-impulse--response-functions" class="section level3">
<h3>3.4.1 IRF (Impulse- response functions)</h3>
<ul>
<li>From [2*] we can obtain the VMA representation in terms of the <span class="math inline">\(\varepsilon _{t}\)</span> shocks:</li>
</ul>
<p><span class="math display">\[y_{t}=C(L)P\varepsilon _{t}\ \ \ \ \ \ \ \ \ \ \ \ [5\ast ]\]</span></p>
<p><span class="math display">\[y_{t}=D(L)\varepsilon _{t}\ \ \ \ \ \ \ \ \ \ \ \ [5]\]</span></p>
<p>being <span class="math inline">\(D(L)=C(L)P\)</span> ,</p>
<p><span class="math inline">\(D(L)=(D_{0}+D_{1}L^{1}+D_{2}L^{2}+D_{3}L^{3}-\ \ ...)\)</span>, with <span class="math inline">\(D_{i}=C_{i}P\)</span> ,</p>
<p>then <span class="math inline">\(D_{0}=C_{0}P=I_{N}P=P\)</span></p>
<ul>
<li><p>As <span class="math inline">\(D_{0}=P\)</span>, and P is lower triangular, the system is recursive: the first shock (<span class="math inline">\(\varepsilon _{t}^{1}\)</span>) could have an instantaneous effect on all the variables of the VAR, while the first variable in the VAR could only be contemporaneously affected by <span class="math inline">\(\varepsilon _{t}^{1}\)</span></p></li>
<li><p>The <span class="math inline">\(D_{i}\)</span> matrices contain the response of the variables to the <span class="math inline">\(\varepsilon _{t}\)</span></p></li>
<li><p>In particular the response of the variable <span class="math inline">\(y_{n}\)</span> to an impulse of size one in <span class="math inline">\(\varepsilon_{m}\)</span> <span class="math inline">\(j\)</span>-periods ahead is given by the <span class="math inline">\((n,m)\)</span><em>-th</em> element of <span class="math inline">\(D_{j}\)</span>.</p></li>
<li><p>Don’t worry too much now firstly because we will usually do this with R and secondly because we are going to practise the calculations by hand at the Lab, but ….</p></li>
<li><p>As an example to illustrate:</p></li>
</ul>
<p><span class="math display">\[y_{t}=\left[ 
\begin{array}{c}
Y_{t} \\ 
P_{t}%
\end{array}%
\right] \ \ \ \varepsilon _{t}=\left[ 
\begin{array}{c}
\varepsilon _{t}^{1} \\ 
\varepsilon _{t}^{2}%
\end{array}%
\right] \]</span></p>
<p><span class="math display">\[y_{t}~=D_{0}\varepsilon _{t}+D_{1}\varepsilon
_{t-1}+D_{2}\varepsilon _{t-2}+D_{3}\varepsilon _{t-3}+D_{4}\varepsilon
_{t-4}+...\]</span></p>
<p><span class="math display">\[y_{t}~=\left[ 
\begin{array}{cc}
0.9 &amp; 0.8 \\ 
0.7 &amp; 0.6%
\end{array}%
\right] \varepsilon _{t}+\left[ 
\begin{array}{cc}
0.5 &amp; 0.4 \\ 
0.3 &amp; 0.2%
\end{array}%
\right] \varepsilon _{t-1}+\left[ 
\begin{array}{cc}
0.1 &amp; -0.1 \\ 
-0.2 &amp; -0.3%
\end{array}%
\right] \varepsilon _{t-2}+...\]</span></p>
<p><span class="math display">\[...+\left[ 
\begin{array}{cc}
-0.4 &amp; -0.5 \\ 
-0.6 &amp; -0.7%
\end{array}%
\right] \varepsilon _{t-3}+D_{4}\varepsilon _{t-4}+...\]</span></p>
<ul>
<li>It would be possible that the element (1,2) of <span class="math inline">\(D_{0}\)</span> were 0.8?</li>
</ul>
<p><br></p>
<hr />
</div>
<div id="fevd-forecast-error-variance-decomposition" class="section level3">
<h3>3.4.2 FEVD (Forecast error variance decomposition)</h3>
<ul>
<li><p>Once we have orthogonalised IRF’s (the <span class="math inline">\(D_{i}\)</span> matrices ), the FEVD can be easily computed. Let’s see how:</p></li>
<li><p>The h-step ahead forecast error can be represented as:</p></li>
</ul>
<p><span class="math display">\[y_{T+h}-y_{T+h\mid T}=D_{0}\varepsilon _{T+h}+D_{1}\varepsilon_{T+h-1}+\cdots +D_{h-1}\varepsilon _{T+1}\]</span></p>
<p>As <span class="math inline">\(\Sigma _{\varepsilon }=I\)</span>, the forecast error variance of the k-th component of <span class="math inline">\(y_{T+h}\)</span> is:</p>
<p><span class="math display">\[\sigma _{k}^{2}(h)=\overset{K}{\underset{j=1}{\sum }}(d_{kj,0}^{2}+\cdots
+d_{kj,h-1}^{2})\]</span></p>
<p>where <span class="math inline">\(d_{nm,j}\)</span> denotes the <span class="math inline">\((n,m)-th\)</span> element of <span class="math inline">\(D_{j}\)</span>.</p>
<ul>
<li><p>The quantity <span class="math inline">\((d_{kj,0}^{2}+\cdots +d_{kj,h-1}^{2})/\sigma _{k}^{2}(h)\)</span> represents the contribution of the <span class="math inline">\(j\)</span>-th shock to the h-step ahead forecast error variance of variable <span class="math inline">\(k\)</span>.</p></li>
<li><p>Don’t worry too much now firstly because we will usually do this with R and secondly because we are going to practise the calculations by hand at the Lab, but ….</p></li>
<li><p>As an example to illustrate:</p></li>
</ul>
<p><span class="math display">\[y_{t}=\left[ 
\begin{array}{c}
Y_{t} \\ 
P_{t}%
\end{array}%
\right] \ \ \ \varepsilon _{t}=\left[ 
\begin{array}{c}
\varepsilon _{t}^{1} \\ 
\varepsilon _{t}^{2}%
\end{array}%
\right] \]</span></p>
<p><span class="math display">\[y_{t}~=D_{0}\varepsilon _{t}+D_{1}\varepsilon
_{t-1}+D_{2}\varepsilon _{t-2}+D_{3}\varepsilon _{t-3}+D_{4}\varepsilon
_{t-4}+...\]</span></p>
<p><span class="math display">\[y_{t}~=\left[ 
\begin{array}{cc}
0.9 &amp; 0.0 \\ 
0.7 &amp; 0.6%
\end{array}%
\right] \varepsilon _{t}+\left[ 
\begin{array}{cc}
0.5 &amp; 0.4 \\ 
0.3 &amp; 0.2%
\end{array}%
\right] \varepsilon _{t-1}+\left[ 
\begin{array}{cc}
0.1 &amp; -0.1 \\ 
-0.2 &amp; -0.3%
\end{array}%
\right] \varepsilon _{t-2}+...\]</span></p>
<p><span class="math display">\[...+\left[ 
\begin{array}{cc}
-0.4 &amp; -0.5 \\ 
-0.6 &amp; -0.7%
\end{array}%
\right] \varepsilon _{t-3}+D_{4}\varepsilon _{t-4}+...\]</span></p>
<p><br> <br></p>
<hr />
</div>
<div id="obtaining-the-irf-fevd-with-r" class="section level3">
<h3>3.4.3 Obtaining the IRF &amp; FEVD (with R)</h3>
<p>Going to the LAB!!</p>
<p><br> <br></p>
<hr />
</div>
<div id="historical-decomposition" class="section level3">
<h3>3.4.4 Historical Decomposition</h3>
<ul>
<li><p>It’s another instrument of the VAR methodology, the third.</p></li>
<li><p>It’s less commonly used than IRF &amp; FEVD</p></li>
<li><p>IRFs show the average response of the model variables to a structural shock (of size 1 standard deviation)</p></li>
<li><p>FEVD quantifies the importance of the different structural shocks in the variability of the data: FEVD gives the percentage of the variance of the error made in forecasting a variable due to a specific shock at a given horizon</p></li>
<li><p>Historical decomposition quantifies the importance of the different shocks to the evolution of the variables in specific periods of time</p></li>
<li><p>SVARs also allow the construction of forecast scenarios conditional on hypothetical sequences of future structural shocks</p></li>
</ul>
<p><br> <br></p>
<hr />
</div>
</div>
</div>
<div id="structural-vars" class="section level1">
<h1>4. Structural VAR’s</h1>
<blockquote>
<p>The success of VAR models as descriptive tools and to some extent as forecasting tools is well established. The ability of structural representations of VAR models to differentiate between correlation and causation, in contrast, has remained contentious <a href="https://ideas.repec.org/p/cpr/ceprdp/8515.html">Kilian(2011), p.1</a></p>
</blockquote>
<div id="introduction-1" class="section level2">
<h2>4.1. Introduction</h2>
<ul>
<li><p>A VAR model can be a good forecasting model but, in the end, it is an atheoretical model (as all the reduced form models are). The raw estimation results for a VAR are rarely interesting. Alternatively, one can represent a VAR as responses to impulses; however, the responses to some steps ahead of innovation(<span class="math inline">\(v_{t}\)</span>) or prediction errors are rarely economically interesting.</p></li>
<li><p>To interpret the VAR in an economically meaningful way, one needs to disentangle the vector of innovations(<span class="math inline">\(v_{t}\)</span>) into “structural” shocks (<span class="math inline">\(\varepsilon _{t}\)</span>), like monetary policy shocks, productivity shocks, etc.,</p></li>
<li><p>Ideally we would like to have: 1) orthogonal shocks 2) shocks with economic meaning.</p></li>
<li><p>That is, we would like to have (identify) a structural VAR (SVAR) like:</p></li>
</ul>
<p><span class="math display">\[B(L)y_{t}=\varepsilon _{t}\ \ \ \ \ \ \ \ \ \ [6]\]</span></p>
<p>where <span class="math inline">\(B(L)=(B_{0}-B_{1}L^{1}-B_{2}L^{2}-...-B_{p}L^{p})\)</span>, <span class="math inline">\(B_{0}\)</span> is a matrix representing the contemporaneous interactions among the endogenous variables and the structural shocks are orthogonal (<span class="math inline">\(\Sigma _{\varepsilon }=I\)</span>).</p>
<ul>
<li>As any stable VAR, we could invert [6] to obtain the structural VMA representation of our SVAR</li>
</ul>
<p><span class="math display">\[y_{t}=D(L)\varepsilon _{t}\ \ \ \ \ \ \ \ \ \ \ \ [5]\]</span></p>
<p>where <span class="math inline">\(D(L)=(D_{0}-D_{1}L^{1}-D_{2}L^{2}-D_{3}L^{3}-\ \ ...)\)</span>, <span class="math inline">\(D_{0}\)</span> is the matrix representing the contemporaneous effects of the shocks, and remember that <span class="math inline">\(\Sigma _{\varepsilon }=I\)</span></p>
<ul>
<li>BUT, how to obtain estimates of the SVAR? We will use our estimation of the VAR model and the relations between the VAR and the SVAR</li>
</ul>
<p><br></p>
<div id="four-representations-of-the-same-dgp" class="section level4">
<h4>Four representations of the same DGP</h4>
<ul>
<li>Remember that we have two models (the VAR &amp; the SVAR), but four representations:</li>
</ul>
<p><span class="math display">\[\begin{array}{ccccc}
A(L)y_{t} &amp; = &amp; v_{t} &amp; \;\;\;\;\;[3] &amp; VAR\\
y_{t} &amp; = &amp; C(L)v_{t} &amp; \;\;\;\;\;[4] &amp; VMA\\
B(L)y_{t} &amp; = &amp; \varepsilon_{t} &amp; \;\;\;\;\;[6] &amp; SVAR\\
y_{t} &amp; = &amp; D(L)\varepsilon_{t} &amp; \;\;\;\;\;[5] &amp; SVMA
\end{array}\]</span></p>
<ul>
<li><p>How to estimate the SVAR? In fact we have already seen the first proposal (Sims) to identify the structural form by means of the Cholesky decomposition but …</p></li>
<li><p>In the previous section we learned that the Cholesky factorization is equivalent to choosing a recursive system of equations. <strong>BUT</strong>, as you can imagine, the order matters: identification is not unique.</p></li>
<li><p>It is important to keep in mind that the “orthogonalization” of the reduced-form residuals by applying a Cholesky decomposition is appropriate only if the recursive structure embodied in P can be justified on economic grounds.</p></li>
<li><p>The distinguishing feature of “orthogonalization” by Cholesky decomposition is that the resulting structural model is recursive (conditional on lagged variables). This means that we impose a particular causal chain rather than learning about causal relationships from the data</p></li>
<li><p>Cooley and LeRoy (1985) criticized the VAR methodology because of its “atheoretical” identification scheme. They argued that Sims did not explicitly justify the identification restrictions and claimed that a model identified by this arbitrary procedure cannot be interpreted as a structural model, because a different variable ordering yields different structural parameters.</p></li>
<li><p>Sims (1986) propose trying different orderings (there are n!) and checking if the results are robust. In general, the higher the elements off-diagonal elements of <span class="math inline">\(\Sigma _{v}\)</span> are, the highrer the cjhanges in the results.</p></li>
<li><p>But, even if there were no differences across these n! specifications, this would only prove that the results are robust among all recursive orderings, but there is no reason for the model to be recursive in the first place.</p></li>
<li><p>Since then, several ways to identify VAR models have been proposed (short-run restrictions, long-run restrictions, cointegration restrictions, sign restriction, narrative approaches etc. ).</p></li>
<li><p>As an alternative to the recursive identification scheme, Bernanke (1986) and Blanchard and Watson (1986) among others introduced non-recursive restrictions on the contemporaneous interactions among variables for identification</p></li>
<li><p>As economic theory often does not provide enough meaningful contemporaneous restrictions (and the more variables you put into your system, the more restrictions you need), the search for additional identifying restrictions led Blanchard and Quah (1989) and subsequently Shapiro and Watson (1988) and Gali (1992) to introduce restrictions on the system’s long-run properties. These long run restrictions are usually based on neutrality postulates</p></li>
<li><p>Faust and Leeper (1997) have criticized the use of long run restrictions to identify structural shocks, and show that unless the economy satisfies some types of strong restrictions, the long run restrictions will be unreliable</p></li>
<li><p>More recently, imposing sign restrictions, allows you to test the implications of all types of restrictions. By dropping one after one of the “dubious restrictions”, one can test whether the responses to shocks are sensitive to the restrictions often imposed</p></li>
<li><p>For a detailed exposition and examples of different sources of identifying restrictions see <a href="https://ideas.repec.org/p/cpr/ceprdp/8515.html">Kilian(2011)</a></p></li>
</ul>
<p><br></p>
<hr />
</div>
</div>
<div id="identifying-the-svar-by-short-run-restrictions-on-the-effects-of-shocks" class="section level2">
<h2>4.2. Identifying the SVAR by short-run restrictions on the effects of shocks</h2>
<ul>
<li><p>If we compare equations [4] and [5], we have that <span class="math inline">\(v_{t}=D_{0}\varepsilon _{t}\)</span></p></li>
<li><p>We obtain a consistent estimation of <span class="math inline">\(v_{t}\)</span> from the estimation of the VAR model [3]. If we could have <span class="math inline">\(D_{0}\)</span> we would be able to recover the structural shocks (<span class="math inline">\(\varepsilon _{t}\)</span>)</p></li>
<li><p>By now, we will recover the structural parameters from the VAR estimates focusing on the impact matrix <span class="math inline">\(D_{0}\)</span> and using the fact that <span class="math inline">\(v_{t}=D_{0}\varepsilon _{t}\)</span>.</p></li>
</ul>
<p><span class="math display">\[E(v_{t}v_{t}^{^{\prime }})=E(D_{0}\varepsilon _{t}\varepsilon
_{t}^{^{\prime }}D_{0}^{^{\prime }})\]</span></p>
<p><span class="math display">\[\Sigma _{v}=D_{0}\Sigma _{\varepsilon }D_{0}^{^{\prime }}\]</span></p>
<p><span class="math display">\[\Sigma _{v}=D_{0}D_{0}^{^{\prime }}\]</span></p>
<ul>
<li><p>The last expression imposes (n*(n+1))/2 restrictions on the elements of <span class="math inline">\(D_{0}\)</span>; that is, we will need n(n-1)/2 additional restrictions to recover estimates of all the elements of <span class="math inline">\(D_{0}\)</span></p></li>
<li><p>Once we have recovered <span class="math inline">\(D_{0}\)</span> and using the fact that <span class="math inline">\(v_{t}=D_{0}\varepsilon _{t}\)</span>, we can write the VAR as <span class="math inline">\(A(L)y_{t}=D_{0}\varepsilon _{t}\)</span> and if we invert the VAR we will recover the SVAR VMA form as <span class="math inline">\(y_{t}=C(L)D_{0}\varepsilon _{t}\)</span> ; that is, we can obtain the structural matrices <span class="math inline">\(D_{i}=C_{i}D_{0}\)</span></p></li>
<li><p>In the terminology of Amisano &amp; Giannini, this way of identification is called a C-model(<span class="math inline">\(v_{t}=C\varepsilon _{t}\)</span>). The <span class="math inline">\(C\)</span> matrix is in fact our <span class="math inline">\(D_{0}\)</span> matrix.</p></li>
<li><p>A particular case of a C-model is the Cholesky approach. Remember that we obtained the Cholesky factor <span class="math inline">\(P\)</span> from <span class="math inline">\(PP^{^{\prime }}=\Sigma _{v}\)</span> and we obtained the <span class="math inline">\(D_{i}=C_{i}P\)</span> ; that is, <span class="math inline">\(P\)</span> is equivalent to our <span class="math inline">\(D_{0}\)</span></p></li>
<li><p>Most short-run restrictions are zero restrictions (e.g., that output reacts only with a lag to monetary shocks).</p></li>
<li><p>The last assumption seems reasonable, but clearly the frequency of the data is of crucial importance: with annual data, a contemporaneous zero restriction is likely to be more debatable than with quarterly or monthly data</p></li>
</ul>
<div id="example-kilian-l.-2009-not-all-oil-price-shocks-are-alike-disentangling-demand-and-supply-shocks-in-the-crude-oil-market-american-economic-review-vol.99" class="section level4">
<h4>Example: Kilian, L. (2009), “Not All Oil Price Shocks Are Alike: Disentangling Demand and Supply Shocks in the Crude Oil Market”, American Economic Review, vol. 99</h4>
<ul>
<li><p>Kilian analyses the global market for crude oil with a trivariate SVAR: <span class="math inline">\(y_{t}=\left[ \Delta Ypetrol_{t},WBC_{t},Ppetrol_{t},\right] ^{^{\prime }}\
\ \ \ \ \ \ \ \ \ \ \ \varepsilon _{t}=\left[ \varepsilon _{t}^{supply},\varepsilon _{t}^{demand},\varepsilon _{t}^{o\_demand}\right]\)</span></p>
<ul>
<li><span class="math inline">\(Ypetrol_{t}\)</span>, is world crude oil production in logs</li>
<li><span class="math inline">\(WBC_{t}\)</span> is a measure of world business cycle (detrended GDP)<br />
</li>
<li><span class="math inline">\(Ppetrol_{t}\)</span> is the log of the real price of oil<br />
</li>
<li><span class="math inline">\(\varepsilon _{t}^{supply}\)</span> is a flow oil supply shock</li>
<li><span class="math inline">\(\varepsilon _{t}^{demand}\)</span> is a flow oil demand shock</li>
<li><span class="math inline">\(\varepsilon _{t}^{o\_demand}\)</span> are other oil demand shocks</li>
<li>Data are monthly</li>
</ul></li>
<li><p>The identification restrictions are modelled in the following matrix</p></li>
</ul>
<p><span class="math display">\[D_{0}=%
\begin{bmatrix}
a &amp; 0 &amp; 0 \\ 
b &amp; c &amp; 0 \\ 
d &amp; e &amp; f%
\end{bmatrix}%
\]</span></p>
<ul>
<li><p>The two demand shocks are identified by the delay restriction that other oil-demand shocks may raise the price of oil, but without slowing down global real economic activity within the same month</p></li>
<li><p>Kilian raises the question whether it would be reasonable to impose an over-identifying restriction of the form <span class="math inline">\(b=0\)</span></p></li>
<li><p>Let’s look at the summary of Kilian’s paper:</p></li>
</ul>
<blockquote>
<p>Shocks to the real price of oil may reflect oil supply shocks, shocks to the global demand for all industrial commodities, or demand shocks that are specific to the crude oil market. Each shock has different effects on the real price of oil and on US macroeconomic aggregates.<br />
Changes in the composition of shocks help explain why regressions of macroeconomic aggregates on oil prices tend to be unstable. Evidence that the recent surge in oil prices was driven primarily by global demand shocks helps explain why this shock so far has failed to cause a major recession in the United States.</p>
</blockquote>
</div>
<div id="example-kilian-2011-pp-11-semi-structural-models-of-monetary-policy" class="section level4">
<h4>Example: Kilian (2011, pp 11), Semi-structural Models of Monetary Policy</h4>
<ul>
<li><p>Often we do not have enough restrictions to fully identify a VAR model.</p></li>
<li><p>If some cases researchers are only interested in identifying a single (or a group) of shocks; as the shocks are orthogonal, the model could be partially identified.</p></li>
<li><p>Then we are using a semi-structural VAR. The most common application is to identify the effects of monetary policy shocks</p></li>
<li><p>For instance we would like to recover the monetary policy shocks from a trivariate VAR: <span class="math inline">\(y_{t}=\left[ \Delta GDP_{t},\pi _{t},i_{t},\right] ^{^{\prime }}\ \ \ \ \ \\ \ \ \ \ \ \ \ \ \ \varepsilon _{t}=\left[ \varepsilon _{t}^{1},\varepsilon_{t}^{2},\varepsilon _{t}^{M}\right]\)</span></p>
<ul>
<li><span class="math inline">\(GDP_{t}\)</span>, is real GDP in logs<br />
</li>
<li><span class="math inline">\(\pi _{t}\)</span> is the inflation rate<br />
</li>
<li><span class="math inline">\(i_{t}\)</span> is the “federal” funds rate (a policy intervention rate)<br />
</li>
<li><span class="math inline">\(\varepsilon _{t}^{1}\)</span> and <span class="math inline">\(\varepsilon _{t}^{2}\)</span> are two unidentified structural shocks<br />
</li>
<li><span class="math inline">\(\varepsilon _{t}^{M}\)</span> is the monetary policy shock</li>
</ul></li>
<li><p>Let’s look at the relations between the innovation and the structural shocks (<span class="math inline">\(\varepsilon _{t}\)</span>)</p></li>
</ul>
<p><span class="math display">\[%
\begin{bmatrix}
u_{t}^{\Delta GDP} \\ 
u_{t}^{\pi } \\ 
u_{t}^{i}%
\end{bmatrix}%
=%
\begin{bmatrix}
a &amp; 0 &amp; 0 \\ 
b &amp; c &amp; 0 \\ 
d &amp; e &amp; f%
\end{bmatrix}%
\begin{bmatrix}
\varepsilon _{t}^{1} \\ 
\varepsilon _{t}^{2} \\ 
\varepsilon _{t}^{M}%
\end{bmatrix}%
\]</span></p>
<ul>
<li><p>The last equation of the model is interpreted as a monetary policy reaction function. The monetary authority responds to <span class="math inline">\(u_{t}^{\Delta GDP}\)</span> and <span class="math inline">\(u_{t}^{\pi }\)</span>, and then the monetary shock (<span class="math inline">\(\varepsilon _{t}^{M}\)</span>) is identified as …</p></li>
<li><p>As we are only interested in the monetary shocks, the other two shocks are not identified. We could do that because any alternative decomposition of the first two shocks would leave <span class="math inline">\(\varepsilon _{t}^{M}\)</span>unaffected. Thus, for simplicity, we impose the recursive structure on the first two equations.</p></li>
<li><p>It is common to enrich the set of variables ordered above the interest rate relative to this simple benchmark model and estimate larger VAR systems. To be aware of the shortcomings and problems with this way of identifying monetary shocks, see page 12 in Kilian(2011)</p></li>
</ul>
<p><br></p>
<hr />
</div>
</div>
<div id="identifying-the-svar-by-long-run-restrictions-on-the-effects-of-shocks" class="section level2">
<h2>4.3. Identifying the SVAR by long-run restrictions on the effects of shocks</h2>
<ul>
<li><p>This approach is really similar to the previous one, but instead of focusing on <span class="math inline">\(D_{0}\)</span> , we concentrate on <span class="math inline">\(D(1)\)</span>, the matrix of long-run impacts of the shocks</p></li>
<li><p>Remember that the matrix of long-run effects (<span class="math inline">\(C(1)=\sum_{i=0}^{\infty}C_{i}\)</span>) could be obtained by inverting the autoregressive polynomial as: <span class="math inline">\(C(1)=(I_{K}-A_{1}-\cdots -A_{p})^{-1}\)</span></p></li>
<li><p>We will recover the structural parameters from the VAR estimates focusing on the long-run impact matrix <span class="math inline">\(D(1)\)</span> and using the fact that <span class="math inline">\(C(1)v_{t}=D(1)\varepsilon _{t}\)</span>.</p></li>
<li><p>Then, as previously:</p></li>
</ul>
<p><span class="math display">\[E(C(1)v_{t}v_{t}^{^{\prime }}C(1)^{^{\prime }})=E(D(1)\varepsilon _{t}\varepsilon
_{t}^{^{\prime }}D(1)^{^{\prime }})\]</span></p>
<p><span class="math display">\[C(1)\Sigma _{v}C(1)^{\prime }=D(1)D(1)^{^{\prime }}\]</span></p>
<ul>
<li><p>Again, the last expression imposes (n+(n+1))/2 restrictions on the elements of <span class="math inline">\(D(1)\)</span>; that is, we will need n(n-1)/2 additional restrictions to recover estimates of all the elements of <span class="math inline">\(D(1)\)</span></p></li>
<li><p>Once we have recovered <span class="math inline">\(D(1)\)</span> and using the fact that <span class="math inline">\(C(1)v_{t}=D(1)\varepsilon _{t}\)</span>, we can write the VAR as <span class="math inline">\(A(L)y_{t}=C(1)^{-1}D(1)\varepsilon _{t}\)</span> and inverting the VAR we will recover the SVAR VMA form as <span class="math inline">\(y_{t}=C(L)C(1)^{-1}D(1)\varepsilon _{t}\)</span> ; that is, we can obtain the structural matrices <span class="math inline">\(D_{i}=C_{i}\ast C(1)^{-1}D(1)\)</span></p></li>
<li><p>This way of identification is also (in the terminology of Amisano &amp; Giannini) a C-model (<span class="math inline">\(v_{t}=C\varepsilon _{t}\)</span>) where <span class="math inline">\(C=C(1)^{-1}D(1)\)</span></p></li>
</ul>
<div id="example-blanchard-and-quah-1989-the-dynamic-effects-of-aggregate-demand-and-supply-disturbances-american-economic-review-vol.794-pages-655-73" class="section level4">
<h4>Example: Blanchard and Quah (1989), “The Dynamic Effects of Aggregate Demand and Supply Disturbances”, American Economic Review, vol. 79(4), pages 655-73</h4>
<ul>
<li>Blanchard and Quah (89) estimate a bivariate VAR with output and unemployment:
<ul>
<li><span class="math inline">\(y_{t}=\left[ \Delta GDP_{t},u_{t}\right] ^{^{\prime }}\)</span></li>
<li><span class="math inline">\(n=2\)</span> , then <span class="math inline">\(n(n-1)/2=1\)</span> ; that is, only a restriction is needed to identify the SVAR</li>
<li>This additional restriction was that the second shock of the VAR (<span class="math inline">\(\varepsilon _{t}^{2}\)</span>) has no long-run effect on real GDP</li>
<li>B&amp;Q(89) interpret <span class="math inline">\(\varepsilon _{t}^{2}\)</span> as a demand shock and <span class="math inline">\(\varepsilon _{t}^{1}\)</span> (which is permitted to have long-run effect on GDP) as a supply shock</li>
</ul></li>
<li><p>There is a greater consensus amongst theoretical models in terms of long-run results. It should be unsurprising, therefore, that the most common set of restrictions is to nullify the long-run response of output to monetary or demand shocks</p></li>
<li><p>Long-run restrictions have been frequently employed, see King et al. (1991), Francis and Ramey (2004), Fisher (2006), among many others.</p></li>
<li><p>It is also possible to adopt a combination of short and long run restrictions as originally demonstrated by Gali (1992), Gerlach and Smets (1995), Peersman and Smets (2001) and Mamoudou et al. (2009).</p></li>
<li><p>Unfortunately, long-run schemes are far from critique-free. Faust and Leeper show that with finite data, the long-run effect of shocks is imprecisely estimated, and that this imprecision is exacerbated by long-run restrictions causing serious bias to IRFs even with large samples.</p></li>
</ul>
<p><br></p>
<hr />
</div>
</div>
<div id="identifying-the-svar-by-restrictions-on-the-contemporaneous-interactions-among-the-endogenous-variables-k-model-in-the-terminology-of-amisano-giannini" class="section level2">
<h2>4.4. Identifying the SVAR by restrictions on the contemporaneous interactions among the endogenous variables (K-model in the terminology of Amisano &amp; Giannini)</h2>
<ul>
<li><p>In this approach the SVAR is identified by restrictions on the contemporaneous interactions among the endogenous variables (<span class="math inline">\(y_{i}\)</span>) instead of restrictions on the effects of the shocks</p></li>
<li><p>The matrix of contemporaneous effects among the (<span class="math inline">\(y_{i}\)</span>) is the <span class="math inline">\(B_{0}\)</span> matrix (called the <span class="math inline">\(K\)</span>-matrix by Amisano &amp; Giannini)</p></li>
<li><p>Comparing the VAR [3] and the SVAR [6], we find that if we look at the variables in t,</p>
<ul>
<li>From the VAR: <span class="math inline">\(y_{t}=v_{t}\)</span></li>
<li>From the SVAR: <span class="math inline">\(B_{0}y_{t}=\varepsilon _{t}\)</span></li>
<li>then, if we pre-multiply the first equation by <span class="math inline">\(B_{0}\)</span></li>
<li>we obtain <span class="math inline">\(B_{0}v_{t}=\varepsilon _{t}\)</span></li>
<li>taking expectations to obtain variance-covariance matrices, <span class="math inline">\(E\left[B_{0}v_{t}v_{t}^{^{\prime }}B_{0}^{^{\prime }}\right] =E\left[\varepsilon_{t}\varepsilon _{t}^{^{\prime }}\right]\)</span></li>
<li>which leads to: <span class="math inline">\(B_{0}\Sigma _{v}B_{0}^{^{\prime }}=I\)</span></li>
</ul></li>
<li><p>The last expression imposes (n+(n+1))/2 restrictions on the elements of <span class="math inline">\(B_{0}\)</span>; that is, we will need n(n-1)/2 additional restrictions to recover estimates of all the elements of <span class="math inline">\(B_{0}\)</span></p></li>
<li><p>Once <span class="math inline">\(B_{0}\)</span> is estimated, we can obtain the SVAR model as: <span class="math inline">\(B_{i}=B_{0}A_{i}\)</span></p></li>
<li><p>We can also obtain the VMA of the SVAR as <span class="math inline">\(D_{i}=C_{i}B_{0}^{-1}\)</span></p></li>
</ul>
<p><br></p>
<hr />
</div>
<div id="identifying-the-svar-by-both-types-of-restrictions-the-ab-model" class="section level2">
<h2>4.5. Identifying the SVAR by both types of restrictions (The AB-model)</h2>
<ul>
<li><p>Amisano &amp; Giannini show how to combine both types of restrictions; that is restrictions on the effects of the shocks and restrictions on the contemporaneous interactions among the <span class="math inline">\(y_{t}\)</span>.</p></li>
<li><p>They call that approach the AB-model, because there are going to appear two matrices ( A &amp; B); in fact, the A and B matrices are the previous K and C matrices in Amisano &amp; Giannini environment</p></li>
<li><p>The <code>vars</code> package uses this AB terminology</p></li>
<li><p>In our environment, [3] to [6], the AB matrices are related to our <span class="math inline">\(B_{0}\)</span> and <span class="math inline">\(D_{0}\)</span> respectively</p></li>
<li><p>These two matrices link the innovations to the structural shocks as <span class="math inline">\(Av_{t}=B\varepsilon _{t}\)</span></p></li>
<li><p>The AB parametrisation nests the C and K models:</p>
<ul>
<li>If <span class="math inline">\(A=I_{n}\)</span> we are in the C-model approach and we only specify restrictions on the effects of the shocks</li>
<li>If <span class="math inline">\(B=I_{n}\)</span> we are in the K-model approach and we only specify restrictions on the contemporaneous relations among the <span class="math inline">\(y_{t}\)</span></li>
</ul></li>
<li><p>To identify the <span class="math inline">\(2n^{2}\)</span> elements of the <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> matrices we need, obviously <span class="math inline">\(2n^{2}\)</span> conditions</p></li>
<li><p>From <span class="math inline">\(Av_{t}=B\varepsilon _{t}\)</span>, we could obtain <span class="math inline">\(Av_{t}v_{t}^{^{\prime }}A^{^{\prime }}=B\varepsilon _{t}\varepsilon _{t}^{^{\prime }}B^{^{\prime }}\)</span> and then taking expectations <span class="math inline">\(A\Sigma _{v}A^{^{\prime }}=BB^{^{\prime }}\)</span> we obtain <span class="math inline">\(n(n-1)/2\)</span> restrictions.</p></li>
<li><p>Then, if we specify an AB-model we will need <span class="math inline">\([2n^{2}-n(n+1)/2]\)</span> extra restrictions to identity our SVAR</p></li>
<li><p>Amisano &amp; Giannini (assuming a Gaussian distribution) explain how to recover the A &amp; B matrices using full information maximum likelihood (FIML) methods. This is the route followed in the vars package.</p></li>
<li><p>This approach involves the maximization of the concentrated likelihood with respect to the structural model parameters subject to the identifying restrictions (see, e.g., Lütkepohl 2005).</p></li>
<li><p>Another alternative is the GMM framework: the identifying restrictions on <span class="math inline">\(B_{0}\)</span> or on <span class="math inline">\(D_{0}\)</span> generate moment conditions that can be used to estimate the unknown coefficients.</p></li>
<li><p>Once we have an estimation of the AB matrices we can recover the SVAR and its VMA representation as:</p>
<ul>
<li><p>The SVAR matrices: <span class="math inline">\(B_{i}=B^{-1}AA_{i}\)</span> , obviously <span class="math inline">\(B_{0}=B^{-1}A\)</span></p></li>
<li><p>The matrices for the SVAR VMA representation: <span class="math inline">\(D_{i}=C_{i}A^{-1}B\)</span>, where <span class="math inline">\(D_{0}=A^{-1}B\)</span></p></li>
</ul></li>
</ul>
<div id="example-blanchard-1989-a-traditional-interpretation-of-macroeconomic-fluctuations-american-economic-review-79-1146-1164." class="section level4">
<h4>Example: Blanchard (1989), “A Traditional Interpretation of Macroeconomic Fluctuations”, American Economic Review, 79, 1146-1164.</h4>
<ul>
<li><p>Blanchard (89) uses a “traditional” Keynesian model to analyse the US macroeconomic fluctuations by means of a structural VAR A-B model.</p></li>
<li><p>Blanchard’s model has 5 equations: an aggregate demand equation, Okun’s law, a price-setting equation, the Phillips curve and a monetary policy rule.</p></li>
<li><p>The VAR has 5 variables and 5 structural shocks:</p></li>
</ul>
<p><span class="math display">\[y_{t}=\left[ Y_{t},U_{t},P_{t},W_{t},M_{t}\right] ^{^{\prime }}\ \ \ \ \ \
\ \ \ \ \ \ \ \ \ \ \varepsilon _{t}=\left[ \varepsilon _{t}^{D},\varepsilon
_{t}^{S},\varepsilon _{t}^{P},\varepsilon _{t}^{W},\varepsilon _{t}^{M}%
\right] ^{^{\prime }}\]</span></p>
<ul>
<li>The A and B matrices to recover the SVAR are:</li>
</ul>
<p><span class="math display">\[A=%
\begin{bmatrix}
1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\ 
a_{21} &amp; 1 &amp; 0 &amp; 0 &amp; 0 \\ 
a_{31} &amp; 0 &amp; 1 &amp; a_{34} &amp; 0 \\ 
0 &amp; a_{42} &amp; a_{43} &amp; 1 &amp; 0 \\ 
a_{51} &amp; a_{52} &amp; a_{53} &amp; a_{54} &amp; 1%
\end{bmatrix}%
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \  \ \ \ \ \ \ \ B=%
\begin{bmatrix}
b_{11} &amp; b_{12} &amp; 0 &amp; 0 &amp; 0 \\ 
0 &amp; b_{22} &amp; 0 &amp; 0 &amp; 0 \\ 
0 &amp; b_{32} &amp; b_{33} &amp; 0 &amp; 0 \\ 
0 &amp; b_{42} &amp; 0 &amp; b_{44} &amp; 0 \\ 
0 &amp; 0 &amp; 0 &amp; 0 &amp; b_{55}%
\end{bmatrix}%
\]</span></p>
<ul>
<li>The restrictions on the A &amp; B matrices come from:
<ul>
<li><span class="math inline">\(Y_{t}=b_{11}\varepsilon _{t}^{D}+b_{12}\varepsilon _{t}^{S}\)</span>. Aggregate demand equation: real GDP is contemporaneously affected by <span class="math inline">\(\varepsilon _{t}^{D}\)</span> and <span class="math inline">\(\varepsilon _{t}^{S}\)</span></li>
<li><span class="math inline">\(U_{t}=-a_{21}Y_{t}+b_{22}\varepsilon _{t}^{S}\)</span>. Okun’s law: unemployment is simultaneously related to output and instantaneously affected by <span class="math inline">\(\varepsilon _{t}^{S}\)</span></li>
<li><span class="math inline">\(P_{t}=-a_{31}Y_{t}-a_{34}W_{t}+b_{32}\varepsilon _{t}^{S}+b_{33}\varepsilon _{t}^{P}\)</span>. Price setting equation: the price level is simultaneously related to output and wages, and instantaneously affected by <span class="math inline">\(\varepsilon _{t}^{S}\)</span> and <span class="math inline">\(\varepsilon _{t}^{P}\)</span></li>
<li><span class="math inline">\(W_{t}=-a_{42}U_{t}-a_{43}P_{t}+b_{42}\varepsilon _{t}^{S}+b_{44}\varepsilon _{t}^{W}\)</span>. Phillips curve: the nominal wage is simultaneously related to unemployment and prices, and instantaneously affected by <span class="math inline">\(\varepsilon _{t}^{S}\)</span> and <span class="math inline">\(\varepsilon _{t}^{P}\)</span></li>
<li><span class="math inline">\(M_{t}=-a_{51}Y_{t}-a_{52}U_{t}-a_{53}P_{t}-a_{54}W_{t}+b_{55}\varepsilon _{t}^{M}\)</span>. Monetary rule equation: nominal money is simultaneously related to all the other 4 variables, but is only and instantaneously affected by monetary structural disturbances(<span class="math inline">\(\varepsilon _{t}^{M}\)</span>)</li>
</ul></li>
<li><p>For a complete economic interpretation of these equations, see Blanchard (1989, section II).</p></li>
<li><p>Together, the 2 matrices (A-B) have 17 free elements, while from <span class="math inline">\(A\Sigma _{v}A^{^{\prime }}=BB^{^{\prime }}\)</span> we obtain only <span class="math inline">\(n(n-1)/2 = 15\)</span> restrictions.To satisfy the order condition we need two additional restrictions.</p></li>
<li><p>For this reason, Blanchard (1989) assigned fixed numerical values to the coefficients <span class="math inline">\(a_{34}\)</span> and <span class="math inline">\(b_{12}\)</span>. The numerical value given to <span class="math inline">\(a_{34}\)</span> was derived from previous studies, whereas that assigned to <span class="math inline">\(b_{12}\)</span> resulted from a sort of calibration reasoning.</p></li>
</ul>
<p><br></p>
<hr />
</div>
</div>
</div>
<div id="additional-topics" class="section level1">
<h1>Additional topics</h1>
<ul>
<li><p>VECM</p></li>
<li><p>Bayesian VARs</p></li>
<li><p>Sign restrictions</p></li>
<li><p>Identification by Heteroskedasticity</p></li>
<li><p>Non-fundamentalness</p></li>
<li><p>Factor-augmented VAR (FAVAR)</p></li>
<li><p>TVAR &amp; STVAR</p></li>
</ul>
<p><br></p>
<hr />
</div>
<div id="to-sum-up" class="section level1">
<h1>To sum up</h1>
<ul>
<li><p>Structural vector autoregressive (SVAR) models have been used extensively for economic analysis since they were advocated by Sims (1980) as alternatives to classical econometric simultaneous equations models.</p></li>
<li><p>Despite their popularity, a number of authors have questioned their reliability and usefulness on different grounds.</p></li>
<li><p>For example, Cooley and LeRoy (1985) call VAR analysis atheoretical if no structural assumptions from economic theory are used in structural interpretations.</p></li>
<li><p>Cooley and Dwyer (1998) question the robustness of the evidence from SVARs with respect to the statistical model specifications.</p></li>
<li><p>Non-arbitrary orthogonalisation schemes which impose contemporaneous restrictions on the VAR are referred to as short-run identification schemes. Most short-run restrictions are zero restrictions (e.g. that output reacts only with a lag to monetary shocks).</p></li>
<li><p>Opinions concerning short-run restrictions are mixed. Faust and Leeper (1997) claim there is often simply an insufficient number of tenable contemporary restrictions to achieve identification. However, Christiano et al. (2006) argue that short-run SVARs perform remarkably well.</p></li>
<li><p>Pioneering work by Shapiro and Watson (1988) and Blanchard and Quah (1989) described how restrictions could be placed on the long-run responses.</p></li>
<li><p>There is a greater consensus amongst theoretical models in terms of long-run results. It should be unsurprising therefore that the most common set of restrictions is to nullify the long-run response of output to monetary shocks.</p></li>
<li><p>Ever since their introduction, long-run restrictions have been frequently employed, see King et al. (1991), Francis and Ramey (2004), Fisher (2006) among many others.</p></li>
<li><p>It is also possible to adopt a combination of short and long run restrictions as originally demonstrated by Gali (1992), Gerlach and Smets (1995), Peersman and Smets (2001) and Mamoudou et al. (2009).</p></li>
<li><p>VAR methodology is under continuous development (VECM, sign restrictions, Heteroskedasticity restrictions, STVAR, etc.)</p></li>
<li><p>In their review of the VAR methodology, <a href="http://www.jstor.org/discover/10.2307/2696519?uid=3737952&amp;uid=2&amp;uid=4&amp;sid=21106079897071">Stock and Watson (2001)</a> conclude that VARs successfully capture the rich interdependent dynamics of data well, but that their structural implications are only as sound as their identification schemes’.</p></li>
</ul>
</div>
<div id="bibliography" class="section level1">
<h1>Bibliography</h1>
<p><strong>The slides are based on the following documents:</strong><br />
(and probably some others that I have not remembered at the time of the final making. Thanks to all of them)</p>
<ul>
<li>Amisano, G., and Giannini, C. (1997). <a href="http://www.springer.com/gp/book/9783662027578">Topics in Structural VAR Econometrics</a>. Springer.</li>
<li>Bjørnland, H. C., and Thorsrud, L. (2015). <a href="http://www.gyldendal.no/Faglitteratur/OEkonomi-og-administrasjon/Samfunnsoekonomi/Applied-time-series-for-macroeconomics-2.-utg">Applied Time Series for Macroeconomics</a>, Gyldendal Akademisk.</li>
<li>Gali, J. (1999), <a href="http://www.crei.cat/wp-content/uploads/users/pages/jgaer99.pdf">Technology, Employment, and the Business Cycle: Do Technology Shocks Explain Aggregate Fluctuations?</a>, American Economic Review, 89, 249-271.</li>
<li>Gottschalk, J. (2001), <a href="https://www.ifw-members.ifw-kiel.de/publications/an-introduction-into-the-svar-methodology-identification-interpretation-and-limitations-of-svar-models/kap1072.pdf">An Introduction into the SVAR Methodology: Identification, Interpretation and Limitations of SVAR models</a>, Kiel Working Paper nº 1072</li>
<li>Kilian, L. (2011), <a href="https://ideas.repec.org/p/cpr/ceprdp/8515.html">Structural Vector Autoregression</a>, CEPR Discussion Paper Series n<sup>o</sup> 8515.</li>
<li>Sims, C.A. (1980), <a href="https://ideas.repec.org/a/ecm/emetrp/v48y1980i1p1-48.html">Macroeconomics and Reality</a>, Econometrica, 48, 1-48</li>
<li>Lütkepohl, H. (2005), <a href="http://www.springer.com/gp/book/9783540401728">New Introduction to Multiple Time Series Analysis</a>. Springer: New York.</li>
<li>Lütkepohl, H. (2011), <a href="http://cadmus.eui.eu/bitstream/handle/1814/19354/ECO_2011_30.pdf">Vector Autoregressive Models</a>, EUI Working Paper ECO2011/30</li>
<li>Pfaff, B. (2008a), <a href="http://www.jstatsoft.org/v27/i04/paper">VAR, SVAR and SVEC Models: Implementation Within R Package vars</a>, Journal of Statistical Software, 27(4)</li>
<li>Pfaff, B. (2008b), <a href="http://www.springer.com/gp/book/9780387759661">Analysis of Integrated and Cointegrated Time Series with R</a>, Springer</li>
<li>Pfaff, B. (2014), <a href="http://cran.r-project.org/web/packages/vars/vars.pdf">Package ‘vars’</a>, CRAN R package.</li>
<li>Stock, J. H. (2008), <a href="http://www.nber.org/WNE/slides7-14-08/Lecture7.pdf">Recent Developments in Structural VAR Modelling</a>, NBER Summer Institute</li>
</ul>
</div>





<footer class="footer">
  <div class="text-muted">-----</div>
  <div class="text-muted"><strong> Web</strong> creada por Pedro J. Pérez, profesor de la Universitat de València. &copy;  2020. If you find any bugs please report them to <a href=”mailto:pedro.j.perez@uv.es”> pedro.j.perez@uv.es</a>.</div>
</footer>


</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
